{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 2.0 GPU vs CPU Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda activate tensorflow_v2_gpu\n",
    "\n",
    "# tensorboard            2.0.2\n",
    "# tensorboard-plugin-wit 1.8.0\n",
    "# tensorflow             2.4.1\n",
    "# tensorflow-estimator   2.0.1\n",
    "# tensorflow-gpu         2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "tf.config.experimental.list_physical_devices(device_type=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                \n",
    "import matplotlib.pyplot as plt\n",
    "import keras as k\n",
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts of x_train : 60000, y_train : 60000, x_test : 10000, y_test : 10000\n"
     ]
    }
   ],
   "source": [
    "#data preprocessing\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "img_rows, img_cols = 28,28\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "x_test=x_test.astype('float32')\n",
    "x_train=x_train.astype('float32')\n",
    "mean=np.mean(x_train)\n",
    "std=np.std(x_train)\n",
    "x_test = (x_test-mean)/std\n",
    "x_train = (x_train-mean)/std\n",
    "\n",
    "print(\"counts of x_train : {}, y_train : {}, x_test : {}, y_test : {}\".format(\n",
    "    len(x_train), len(y_train), len(x_test), len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts of x_train : 60000, y_train : 60000, x_test : 10000, y_test : 10000\n"
     ]
    }
   ],
   "source": [
    "#labels\n",
    "num_classes=10\n",
    "y_train = k.utils.np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = k.utils.np_utils.to_categorical(y_test, num_classes)\n",
    "print(\"counts of x_train : {}, y_train : {}, x_test : {}, y_test : {}\".format(\n",
    "    len(x_train), len(y_train), len(x_test), len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow with CPU only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\G S SRENATH KUMAR\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "num_filter=32\n",
    "num_dense=512\n",
    "drop_dense=0.7\n",
    "ac='relu'\n",
    "learningrate=0.001\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(num_filter, (3, 3), activation=ac, input_shape=(28, 28, 1),padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Conv2D(num_filter, (3, 3), activation=ac,padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))   # reduces to 14x14x32\n",
    "\n",
    "    model.add(Conv2D(2*num_filter, (3, 3), activation=ac,padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Conv2D(2*num_filter, (3, 3), activation=ac,padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))   # reduces to 7x7x64 = 3136 neurons\n",
    "\n",
    "    model.add(Flatten())                        \n",
    "    model.add(Dense(num_dense, activation=ac))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(drop_dense))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    adm=Adam(lr=learningrate, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=adm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size 8\n",
      " 309/7500 [>.............................] - ETA: 1:38 - loss: 0.7019 - accuracy: 0.7832"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch size \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(k))\n\u001b[0;32m      7\u001b[0m t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m t2 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     10\u001b[0m cpu_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mint\u001b[39m(t2\u001b[38;5;241m-\u001b[39mt1))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\keras\\engine\\training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1178\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1179\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1180\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1181\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1182\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1183\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1184\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1186\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    914\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    915\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 917\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    920\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    921\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   3037\u001b[0m   (graph_function,\n\u001b[0;32m   3038\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1961\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1962\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1963\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1964\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1965\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m     args,\n\u001b[0;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1968\u001b[0m     executing_eagerly)\n\u001b[0;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    597\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cpu_list=[]\n",
    "batch_sizes = []\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    for i in range(0,7):\n",
    "        k=8*2**i\n",
    "        print(\"batch size \"+str(k))\n",
    "        t1 = time.time()\n",
    "        model.fit(x_train, y_train, batch_size=k, epochs=1, validation_data=(x_test, y_test))\n",
    "        t2 = time.time()\n",
    "        cpu_list.append(int(t2-t1))\n",
    "        batch_sizes.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu_list :  [110, 88, 77, 59, 51, 49, 48]\n"
     ]
    }
   ],
   "source": [
    "print(\"cpu_list : \", cpu_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow with GPU only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\G S SRENATH KUMAR\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#build model\n",
    "\n",
    "num_filter=32\n",
    "num_dense=512\n",
    "drop_dense=0.7\n",
    "ac='relu'\n",
    "learningrate=0.001\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(num_filter, (3, 3), activation=ac, input_shape=(28, 28, 1),padding='same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Conv2D(num_filter, (3, 3), activation=ac,padding='same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))   # reduces to 14x14x32\n",
    "\n",
    "model.add(Conv2D(2*num_filter, (3, 3), activation=ac,padding='same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Conv2D(2*num_filter, (3, 3), activation=ac,padding='same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))   # reduces to 7x7x64 = 3136 neurons\n",
    "\n",
    "model.add(Flatten())                        \n",
    "model.add(Dense(num_dense, activation=ac))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(drop_dense))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "adm=Adam(lr=learningrate, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=adm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train the model with gpu or cpu for different batch sizes. The larger the batch size, the more the parallelisation of matrix multiplications in the gpu speeds up the training compared to the cpu. The gpu load goes up to 95 percent for batch size 512, with 1.6GB used. Much larger batches require better graphics cards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # with GPU (the default in my setup)\n",
    "# for i in range(1,2):\n",
    "#     k=8*2**i\n",
    "#     print(\"batch size \"+str(k))\n",
    "#     model.fit(x_train, y_train, batch_size=k, epochs=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_list :  []\n",
      "batch size 8\n",
      "7500/7500 [==============================] - 46s 5ms/step - loss: 0.2305 - accuracy: 0.9315 - val_loss: 0.0523 - val_accuracy: 0.9831\n",
      "batch size 16\n",
      "3750/3750 [==============================] - 22s 6ms/step - loss: 0.0755 - accuracy: 0.9782 - val_loss: 0.0424 - val_accuracy: 0.9869\n",
      "batch size 32\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0445 - accuracy: 0.9871 - val_loss: 0.0206 - val_accuracy: 0.9942\n",
      "batch size 64\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.0243 - accuracy: 0.9924 - val_loss: 0.0159 - val_accuracy: 0.9948\n",
      "batch size 128\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.0146 - val_accuracy: 0.9950\n",
      "batch size 256\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0122 - accuracy: 0.9966 - val_loss: 0.0129 - val_accuracy: 0.9963\n",
      "batch size 512\n",
      "118/118 [==============================] - 2s 17ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.0134 - val_accuracy: 0.9960\n"
     ]
    }
   ],
   "source": [
    "gpu_list=[]\n",
    "batch_sizes = []\n",
    "print(\"gpu_list : \", gpu_list)\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    for i in range(0,7):\n",
    "        k=8*2**i\n",
    "        print(\"batch size \"+str(k))\n",
    "        t1 = time.time()\n",
    "        model.fit(x_train, y_train, batch_size=k, epochs=1, validation_data=(x_test, y_test))\n",
    "        t2 = time.time()\n",
    "        gpu_list.append(int(t2-t1))\n",
    "        batch_sizes.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_list :  []\n",
      "batch size 8\n",
      " 822/7500 [==>...........................] - ETA: 33s - loss: 0.4981 - accuracy: 0.8508"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch size \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(k))\n\u001b[0;32m      8\u001b[0m t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 9\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m t2 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     11\u001b[0m gpu_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mint\u001b[39m(t2\u001b[38;5;241m-\u001b[39mt1))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\keras\\engine\\training.py:1189\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1187\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs  \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1189\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1191\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\keras\\callbacks.py:435\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    429\u001b[0m \n\u001b[0;32m    430\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 435\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\keras\\callbacks.py:295\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    293\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 295\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    297\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(hook))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\keras\\callbacks.py:315\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    312\u001b[0m   batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    313\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 315\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    318\u001b[0m   end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\keras\\callbacks.py:353\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    352\u001b[0m   hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 353\u001b[0m   \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    356\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\keras\\callbacks.py:1028\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1028\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\keras\\callbacks.py:1100\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1096\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1099\u001b[0m   \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1100\u001b[0m   logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1101\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\keras\\utils\\tf_utils.py:516\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(x) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[0;32m    514\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t  \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m--> 516\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:869\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    866\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 869\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    870\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:869\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    865\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    866\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 869\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    870\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\keras\\utils\\tf_utils.py:512\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    511\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 512\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(x) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[0;32m    514\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1094\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m \n\u001b[0;32m   1073\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1094\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1060\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1058\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1059\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1060\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1061\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1062\u001b[0m     six\u001b[38;5;241m.\u001b[39mraise_from(core\u001b[38;5;241m.\u001b[39m_status_to_exception(e\u001b[38;5;241m.\u001b[39mcode, e\u001b[38;5;241m.\u001b[39mmessage), \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gpu_list=[]\n",
    "batch_sizes = []\n",
    "print(\"gpu_list : \", gpu_list)\n",
    "\n",
    "for i in range(0,7):\n",
    "    k=8*2**i\n",
    "    print(\"batch size \"+str(k))\n",
    "    t1 = time.time()\n",
    "    model.fit(x_train, y_train, batch_size=k, epochs=1, validation_data=(x_test, y_test))\n",
    "    t2 = time.time()\n",
    "    gpu_list.append(int(t2-t1))\n",
    "    batch_sizes.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_list :  [40, 23, 11, 5, 3, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"gpu_list : \", gpu_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1 :-  GPU VS CPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cpu_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# plot the comparison. The training with gpu is faster by a factor of about 4-6\u001b[39;00m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(batch_sizes,gpu_list,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbo\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(batch_sizes,\u001b[43mcpu_list\u001b[49m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(batch_sizes,gpu_list,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb--\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(batch_sizes,cpu_list,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr--\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cpu_list' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the comparison. The training with gpu is faster by a factor of about 4-6\n",
    "plt.plot(batch_sizes,gpu_list,'bo')\n",
    "plt.plot(batch_sizes,cpu_list,'ro')\n",
    "plt.plot(batch_sizes,gpu_list,'b--')\n",
    "plt.plot(batch_sizes,cpu_list,'r--')\n",
    "plt.ylabel('training time per epoch (s)')\n",
    "plt.xlabel('batch size')\n",
    "plt.legend(['gpu', 'cpu'], loc='upper right')\n",
    "plt.ylim([0,400])\n",
    "#plt.savefig('CPUvsGPU.png') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2 :-  GPU VS CPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the comparison. The training with gpu is faster by a factor of about 4-6\n",
    "plt.plot(batch_sizes,gpu_list,'bo')\n",
    "plt.plot(batch_sizes,cpu_list,'ro')\n",
    "plt.plot(batch_sizes,gpu_list,'b--')\n",
    "plt.plot(batch_sizes,cpu_list,'r--')\n",
    "plt.ylabel('training time per epoch (s)')\n",
    "plt.xlabel('batch size')\n",
    "plt.legend(['gpu', 'cpu'], loc='upper right')\n",
    "plt.ylim([0,400])\n",
    "#plt.savefig('CPUvsGPU.png') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.6545454545454548,\n",
       " 5.733333333333333,\n",
       " 7.833333333333333,\n",
       " 9.416666666666666,\n",
       " 12.333333333333334,\n",
       " 16.428571428571427,\n",
       " 19.5]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio_list=[j/k for (j, k) in zip(cpu_list,gpu_list)]\n",
    "ratio_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
